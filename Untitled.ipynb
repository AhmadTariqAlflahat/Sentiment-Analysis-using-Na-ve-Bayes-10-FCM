{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_neg = glob.glob('imdb1/neg/cv*.txt')\n",
    "path_pos = glob.glob('imdb1/pos/cv*.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_list, pos_list = [],[]\n",
    "for _file_neg, _file_pos in zip(path_neg, path_pos):\n",
    "    with open(_file_neg) as _open_neg, open(_file_pos) as _open_pos:\n",
    "        neg_list.append(_open_neg.readlines())\n",
    "        pos_list.append(_open_pos.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "pos_list_n = list(itertools.chain(*pos_list))\n",
    "neg_list_n = list(itertools.chain(*neg_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_df = pd.DataFrame(pos_list_n)\n",
    "pos_df['class'] = np.ones((pos_df.shape[0],), dtype=int)\n",
    "pos_df.columns = ['review', 'class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_df = pd.DataFrame(neg_list_n)\n",
    "neg_df['class'] = np.zeros((neg_df.shape[0],), dtype=int)\n",
    "neg_df.columns = ['review', 'class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_data(text):\n",
    "    text = str(text)\n",
    "    text = re.sub('\\n', ' ', text)\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    text = re.sub('  ', ' ', text)\n",
    "    return text\n",
    "clean_round = lambda x: clean_data(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict \n",
    "\n",
    "def removeDupWithoutOrder(str): \n",
    "    return \"\".join(OrderedDict.fromkeys(str))  \n",
    "duplicate_round = lambda x: removeDupWithoutOrder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([pos_df,neg_df], axis=0, ignore_index=True)\n",
    "data['reviewCleaned'] = pd.DataFrame(data.review.apply(clean_round))\n",
    "data['review_naduplicate'] = pd.DataFrame(data.review.apply(duplicate_round))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>class</th>\n",
       "      <th>reviewCleaned</th>\n",
       "      <th>review_naduplicate</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>films adapted from comic books have had plenty...</td>\n",
       "      <td>1</td>\n",
       "      <td>films adapted from comic books have had plenty...</td>\n",
       "      <td>films adpterocbkhvnyu,w'()g.\\n</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>for starters , it was created by alan moore ( ...</td>\n",
       "      <td>1</td>\n",
       "      <td>for starters  it was created by alan moore  an...</td>\n",
       "      <td>for stae,iwcdbylnm(p)hugv'8012-.\\n</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>to say moore and campbell thoroughly researche...</td>\n",
       "      <td>1</td>\n",
       "      <td>to say moore and campbell thoroughly researche...</td>\n",
       "      <td>to saymrendcpblhugjfkiw.\\n</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>the book ( or \" graphic novel , \" if you will ...</td>\n",
       "      <td>1</td>\n",
       "      <td>the book  or  graphic novel   if you will  is ...</td>\n",
       "      <td>the bok(r\"gapicnvl,fyuw)s50d3m.\\n</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>in other words , don't dismiss this film becau...</td>\n",
       "      <td>1</td>\n",
       "      <td>in other words  don t dismiss this film becaus...</td>\n",
       "      <td>in otherwds,'mflbcau.\\n</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  class  \\\n",
       "0  films adapted from comic books have had plenty...      1   \n",
       "1  for starters , it was created by alan moore ( ...      1   \n",
       "2  to say moore and campbell thoroughly researche...      1   \n",
       "3  the book ( or \" graphic novel , \" if you will ...      1   \n",
       "4  in other words , don't dismiss this film becau...      1   \n",
       "\n",
       "                                       reviewCleaned  \\\n",
       "0  films adapted from comic books have had plenty...   \n",
       "1  for starters  it was created by alan moore  an...   \n",
       "2  to say moore and campbell thoroughly researche...   \n",
       "3  the book  or  graphic novel   if you will  is ...   \n",
       "4  in other words  don t dismiss this film becaus...   \n",
       "\n",
       "                   review_naduplicate  count  \n",
       "0      films adpterocbkhvnyu,w'()g.\\n     53  \n",
       "1  for stae,iwcdbylnm(p)hugv'8012-.\\n     37  \n",
       "2          to saymrendcpblhugjfkiw.\\n     28  \n",
       "3   the bok(r\"gapicnvl,fyuw)s50d3m.\\n     31  \n",
       "4             in otherwds,'mflbcau.\\n     14  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_vector(text):\n",
    "    count = len(re.split(' ', text))\n",
    "    return count\n",
    "\n",
    "count_round = lambda x: count_vector(x)\n",
    "data['count'] = pd.DataFrame(data.review.apply(count_round))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Text As it's ------\n",
      "0.4527194066749073\n",
      "0.4624536464771323\n",
      "0.4445302843016069\n",
      "0.45750927070457353\n",
      "0.43139678615574784\n",
      "0.4408220024721879\n",
      "0.35058714462299134\n",
      "0.35939431396786153\n",
      "0.3666563658838072\n",
      "0.36341161928306553\n",
      "[[11696. 20087.]\n",
      " [17907. 15030.]]\n",
      "------ Removeing Stop Words ------\n",
      "0.4780593325092707\n",
      "0.484548825710754\n",
      "0.47141532756489496\n",
      "0.4791409147095179\n",
      "0.4530284301606922\n",
      "0.45488257107540175\n",
      "0.3777812113720643\n",
      "0.3855067985166873\n",
      "0.3977132262051916\n",
      "0.39137824474660077\n",
      "[[12533. 19250.]\n",
      " [17165. 15772.]]\n",
      "------ Duplicate Removed ------\n",
      "0.01993201483312732\n",
      "0.023022249690976514\n",
      "0.011588380716934486\n",
      "0.014678615574783683\n",
      "0.010352286773794808\n",
      "0.10599505562422744\n",
      "0.015451174289245983\n",
      "0.015451174289245983\n",
      "0.022867737948084055\n",
      "0.010352286773794808\n",
      "[[  529. 31254.]\n",
      " [31850.  1087.]]\n",
      "------ Bigram Feature ------\n",
      "0.34085290482076636\n",
      "0.36016687268232384\n",
      "0.33420889987639063\n",
      "0.34517923362175523\n",
      "0.3318912237330037\n",
      "0.36418417799752784\n",
      "0.27796662546353523\n",
      "0.2804388133498146\n",
      "0.2835290482076638\n",
      "0.28831891223733\n",
      "[[ 9201. 22582.]\n",
      " [21384. 11553.]]\n",
      "------ Trigrams Feature ------\n",
      "0.0942521631644005\n",
      "0.10939431396786156\n",
      "0.09533374536464771\n",
      "0.10105067985166873\n",
      "0.08714462299134734\n",
      "0.17243510506798518\n",
      "0.0842088998763906\n",
      "0.07648331273176762\n",
      "0.08668108776266996\n",
      "0.0761742892459827\n",
      "[[ 2659. 29124.]\n",
      " [29233.  3704.]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def MNBCrossFold(df, k, column=[], _class='class', **kwargs):\n",
    "    vect = TfidfVectorizer(**kwargs)\n",
    "    _nb_model = MultinomialNB(alpha=1.0, fit_prior=True)\n",
    "    \n",
    "    X, y = df[column], df[_class]\n",
    "    kf = KFold(n_splits=k)\n",
    "    kf.get_n_splits(X)\n",
    "    confusion_sum = np.zeros((2, 2))\n",
    "    for train_index, test_index in kf.split(X):\n",
    "    #     print('TRAIN:', len(train_index), 'TEST:', len(test_index))\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        vect.fit(X_train)\n",
    "        X_train_dtm = vect.transform(X_train)\n",
    "        X_train_dtm = vect.fit_transform(X_train)\n",
    "        X_test_dtm = vect.transform(X_test)\n",
    "\n",
    "        _nb_model.fit(X_train_dtm, y_train)\n",
    "        y_pred_class = _nb_model.predict(X_test_dtm)\n",
    "        print(metrics.accuracy_score(y_test, y_pred_class))\n",
    "#         print(confusion_matrix(y_test, y_pred_class))\n",
    "        confusion_sum = np.add(confusion_sum, confusion_matrix(y_test, y_pred_class))\n",
    "    print(confusion_sum)\n",
    "\n",
    "print('------ Text As it\\'s ------')\n",
    "MNBCrossFold(data, k=10, column = 'review')\n",
    "print('------ Removeing Stop Words ------')\n",
    "MNBCrossFold(data, k=10, column = 'reviewCleaned', stop_words='english')\n",
    "print('------ Duplicate Removed ------')\n",
    "MNBCrossFold(data, k=10, column = 'review_naduplicate', stop_words='english', ngram_range=(2, 2), lowercase=True)\n",
    "print('------ Bigram Feature ------')\n",
    "MNBCrossFold(data, k=10, column = 'review', stop_words='english', ngram_range=(2, 2), lowercase=True)\n",
    "print('------ Trigrams Feature ------')\n",
    "MNBCrossFold(data, k=10, column = 'review', stop_words='english', ngram_range=(3, 3), lowercase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".....ll9\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
